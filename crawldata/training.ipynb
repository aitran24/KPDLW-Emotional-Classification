{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /home/aitran/.local/lib/python3.10/site-packages (8.1.6)\n",
      "Requirement already satisfied: jupyter in /home/aitran/.local/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/aitran/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/aitran/.local/lib/python3.10/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in /home/aitran/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/aitran/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/aitran/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: notebook in /home/aitran/.local/lib/python3.10/site-packages (from jupyter) (7.4.0)\n",
      "Requirement already satisfied: jupyter-console in /home/aitran/.local/lib/python3.10/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /home/aitran/.local/lib/python3.10/site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: jupyterlab in /home/aitran/.local/lib/python3.10/site-packages (from jupyter) (4.4.0)\n",
      "Requirement already satisfied: ipykernel in /home/aitran/.local/lib/python3.10/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: stack_data in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: exceptiongroup in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: decorator in /home/aitran/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: psutil in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (6.4.2)\n",
      "Requirement already satisfied: packaging in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (24.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/aitran/.local/lib/python3.10/site-packages (from ipykernel->jupyter) (1.8.12)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.15.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /usr/lib/python3/dist-packages (from jupyterlab->jupyter) (59.6.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: nbformat>=5.7 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: bleach[css]!=5.0.0 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: defusedxml in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/aitran/.local/lib/python3.10/site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: webencodings in /home/aitran/.local/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/aitran/.local/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/aitran/.local/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.8)\n",
      "Requirement already satisfied: anyio in /home/aitran/.local/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2020.6.20)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/aitran/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/aitran/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (23.1.0)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /home/aitran/.local/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/aitran/.local/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in /home/aitran/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/aitran/.local/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: pure-eval in /home/aitran/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/aitran/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/aitran/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/aitran/.local/lib/python3.10/site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/aitran/.local/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2024.10.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.24.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /home/aitran/.local/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/lib/python3/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aitran/.local/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aitran/.local/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/lib/python3/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.7.0)\n",
      "Requirement already satisfied: fqdn in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: isoduration in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /home/aitran/.local/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/aitran/.local/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/aitran/.local/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/aitran/.local/lib/python3.10/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/aitran/.local/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.9.0.20241206)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Number of classes: 3\n",
      "Class names: ['Tiêu cực', 'Trung bình', 'Tích cực']\n"
     ]
    }
   ],
   "source": [
    "# Không cần openpyxl vì là file CSV\n",
    "# !pip install openpyxl -q\n",
    "# For Vietnamese word_segment\n",
    "!pip install pyvi -q\n",
    "# Transformers library from Hugging Face\n",
    "!pip install transformers[torch] -q # Cài đặt kèm PyTorch\n",
    "# Cài đặt scikit-learn để dùng StratifiedKFold và metrics\n",
    "!pip install scikit-learn -q\n",
    "# Cài đặt seaborn và matplotlib để vẽ biểu đồ\n",
    "!pip install seaborn matplotlib -q\n",
    "# Cài đặt gensim để dùng simple_preprocess\n",
    "!pip install gensim -q\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pyvi import ViTokenizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup, AutoTokenizer, AutoModel, logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.set_verbosity_error() # Chỉ hiển thị lỗi từ thư viện transformers\n",
    "\n",
    "# --- Constants ---\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LEN = 180 # Xem xét lại sau khi chạy Cell 4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- File and Column Names ---\n",
    "CSV_FILE_PATH = 'reviews_AT.csv'\n",
    "COMMENT_COLUMN = 'Comment'\n",
    "LABEL_COLUMN = 'Label' # Cột chứa nhãn số (0, 1, 2 - GIẢ ĐỊNH)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# --- Reproducibility ---\n",
    "def seed_everything(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Định nghĩa số lớp và tên lớp ---\n",
    "# *** SỬA ĐỔI CHO 3 LỚP ***\n",
    "N_CLASSES = 3\n",
    "# GIẢ ĐỊNH: 0 = Tiêu cực, 1 = Trung bình, 2 = Tích cực. Kiểm tra lại file CSV!\n",
    "CLASS_NAMES = ['Tiêu cực', 'Trung bình', 'Tích cực']\n",
    "print(f\"Number of classes: {N_CLASSES}\")\n",
    "print(f\"Class names: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read CSV file: reviews_AT.csv\n",
      "Original number of samples: 2561\n",
      "Number of samples after cleaning: 2561\n",
      "\n",
      "Label distribution:\n",
      "Label\n",
      "0     574\n",
      "1     434\n",
      "2    1553\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data with kfold column:\n",
      "                                               Sentence  Label  kfold\n",
      "2157                             Bình gọn đẹp, xài khoẻ      2      4\n",
      "1738  sản phẩm dùng tốt, mua cho người thân sử dụng,...      2      3\n",
      "1173  tạm ổn sủ dụng nhu cầu gia đình ép vẫn hơi bã ...      2      0\n",
      "478       quá tuyệt sẽ giới thiệu cho bạn bè người thân      2      0\n",
      "1356  máy ép ra cặn quá nhiều, không xứng với giá ti...      0      3\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2561 entries, 0 to 2560\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2561 non-null   object\n",
      " 1   Label     2561 non-null   int64 \n",
      " 2   kfold     2561 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 60.1+ KB\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_and_prepare_data(path, comment_col, label_col):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Successfully read CSV file: {path}\")\n",
    "        print(f\"Original number of samples: {len(df)}\")\n",
    "\n",
    "        if comment_col not in df.columns or label_col not in df.columns:\n",
    "             raise ValueError(f\"Missing required columns: '{comment_col}' or '{label_col}'\")\n",
    "\n",
    "        # Chọn cột, đổi tên, xử lý NaN và kiểu dữ liệu\n",
    "        df = df[[comment_col, label_col]].copy()\n",
    "        df.columns = ['Sentence', 'Label'] # Đổi tên cột nhãn thành 'Label'\n",
    "        df.dropna(subset=['Sentence', 'Label'], inplace=True)\n",
    "        df['Sentence'] = df['Sentence'].astype(str)\n",
    "        df['Label'] = df['Label'].astype(int) # Nhãn đã là số (0, 1, 2)\n",
    "\n",
    "        # *** BỎ BƯỚC MAPPING NHÃN ***\n",
    "\n",
    "        # Chỉ giữ lại các nhãn hợp lệ (0, 1, 2)\n",
    "        valid_labels = list(range(N_CLASSES)) # Tạo danh sách [0, 1, 2]\n",
    "        original_count = len(df)\n",
    "        df = df[df['Label'].isin(valid_labels)]\n",
    "        removed_count = original_count - len(df)\n",
    "        if removed_count > 0:\n",
    "            print(f\"Warning: Removed {removed_count} samples with invalid labels (not in {valid_labels}).\")\n",
    "\n",
    "\n",
    "        # Bỏ comment rỗng\n",
    "        df = df[df['Sentence'].str.strip().str.len() > 0]\n",
    "\n",
    "        print(f\"Number of samples after cleaning: {len(df)}\")\n",
    "        if len(df) == 0:\n",
    "             print(\"Error: No valid data remaining after cleaning.\")\n",
    "             return None\n",
    "\n",
    "\n",
    "        print(\"\\nLabel distribution:\")\n",
    "        print(df['Label'].value_counts().sort_index()) # Sắp xếp theo index (0, 1, 2)\n",
    "\n",
    "\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{path}'\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error: {ve}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during data loading: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Load dữ liệu từ file CSV của bạn\n",
    "all_df = load_and_prepare_data(CSV_FILE_PATH, COMMENT_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "\n",
    "if all_df is not None:\n",
    "    # --- Tạo cột K-Fold ---\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    # Sử dụng cột 'Label' (0, 1, 2) để stratify\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(X=all_df, y=all_df['Label'])):\n",
    "        all_df.loc[val_idx, \"kfold\"] = fold\n",
    "    all_df['kfold'] = all_df['kfold'].astype(int)\n",
    "\n",
    "\n",
    "    print(\"\\nSample data with kfold column:\")\n",
    "    print(all_df.sample(5))\n",
    "\n",
    "\n",
    "    print(\"\\nData Info:\")\n",
    "    all_df.info()\n",
    "\n",
    "\n",
    "    # Vẽ biểu đồ phân bố nhãn\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x='Label', data=all_df, order=sorted(all_df['Label'].unique()))\n",
    "    plt.title('Label Distribution')\n",
    "    # Gán tên lớp cho trục x\n",
    "    plt.xticks(ticks=range(N_CLASSES), labels=CLASS_NAMES)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nCould not load data. Please check the file path and column names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhoBERT tokenizer loaded successfully.\n",
      "SentimentDataset class defined (using original 0, 1, 2 labels).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer PhoBERT\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "    print(\"PhoBERT tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading tokenizer: {e}\")\n",
    "    # exit()\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=MAX_LEN):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        try:\n",
    "            text = row['Sentence']\n",
    "            # *** LẤY NHÃN GỐC (0, 1, 2) TỪ CỘT 'Label' ***\n",
    "            label = row['Label']\n",
    "\n",
    "            # Tiền xử lý văn bản\n",
    "            processed_text = ' '.join(simple_preprocess(text))\n",
    "            tokenized_text = ViTokenizer.tokenize(processed_text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data at index {index}: {e}\")\n",
    "            return None\n",
    "\n",
    "        # Encode văn bản\n",
    "        try:\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                tokenized_text,\n",
    "                truncation=True,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=False,\n",
    "                return_tensors='pt',\n",
    "            )\n",
    "        except Exception as e:\n",
    "             print(f\"Error encoding text at index {index}: '{tokenized_text[:50]}...'. Error: {e}\")\n",
    "             return None\n",
    "\n",
    "        return {\n",
    "            'text': tokenized_text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_masks': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(label, dtype=torch.long), # Nhãn gốc đã là số (0, 1, 2)\n",
    "        }\n",
    "\n",
    "# Hàm collate_fn (giữ nguyên)\n",
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "    elem = batch[0]\n",
    "    keys = elem.keys()\n",
    "    collated_batch = {}\n",
    "    for key in keys:\n",
    "        if key == 'text':\n",
    "            collated_batch[key] = [d[key] for d in batch]\n",
    "        else:\n",
    "            collated_batch[key] = torch.stack([d[key] for d in batch])\n",
    "    return collated_batch\n",
    "\n",
    "print(\"SentimentDataset class defined (using original 0, 1, 2 labels).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Check Max Length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing token lengths for the dataset...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested MAX_LEN: Consider a value around 46 (95th) or 91 (99th).\n",
      "Current MAX_LEN is set to: 180\n"
     ]
    }
   ],
   "source": [
    "if all_df is not None:\n",
    "    print(\"Analyzing token lengths for the dataset...\")\n",
    "    all_sentences = all_df['Sentence'].tolist()\n",
    "    processed_sentences = [' '.join(simple_preprocess(text)) for text in all_sentences]\n",
    "    tokenized_vi_sentences = [ViTokenizer.tokenize(text) for text in processed_sentences]\n",
    "    encoded_texts = [tokenizer.encode(text, add_special_tokens=True) for text in tokenized_vi_sentences]\n",
    "    token_lens = [len(text) for text in encoded_texts]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(token_lens, bins=50, kde=True)\n",
    "    percentile_95 = np.percentile(token_lens, 95)\n",
    "    percentile_99 = np.percentile(token_lens, 99)\n",
    "    plt.xlim([0, max(token_lens) + 10])\n",
    "    plt.xlabel('Token Count per Sentence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Token Counts per Sentence')\n",
    "    plt.axvline(MAX_LEN, color='red', linestyle='dashed', linewidth=1, label=f'Chosen MAX_LEN={MAX_LEN}')\n",
    "    plt.axvline(percentile_95, color='orange', linestyle='dashed', linewidth=1, label=f'95th Percentile={percentile_95:.0f}')\n",
    "    plt.axvline(percentile_99, color='green', linestyle='dashed', linewidth=1, label=f'99th Percentile={percentile_99:.0f}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Suggested MAX_LEN: Consider a value around {percentile_95:.0f} (95th) or {percentile_99:.0f} (99th).\")\n",
    "    print(f\"Current MAX_LEN is set to: {MAX_LEN}\")\n",
    "else:\n",
    "    print(\"Cannot analyze token lengths because data loading failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentClassifier class defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=N_CLASSES): # Sử dụng N_CLASSES=3 từ config\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        print(f\"Initializing SentimentClassifier for {n_classes} classes...\")\n",
    "        try:\n",
    "            self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "            print(\"Pre-trained PhoBERT base model loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading PhoBERT model: {e}\")\n",
    "            raise\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "        print(f\"Classifier head initialized.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        pooler_output = outputs.pooler_output\n",
    "        x = self.drop(pooler_output)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "print(\"SentimentClassifier class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Evaluation functions defined (using basic tqdm).\n"
     ]
    }
   ],
   "source": [
    "# # Import tqdm nếu chưa import\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# def train_epoch(model, criterion, optimizer, scheduler, train_loader, epoch, n_epochs, device):\n",
    "#     model.train()\n",
    "#     losses = []\n",
    "#     correct_predictions = 0\n",
    "#     total_samples = 0\n",
    "#     progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs} [Train]', leave=False)\n",
    "\n",
    "#     for data in progress_bar:\n",
    "#         if data is None: continue\n",
    "#         input_ids = data['input_ids'].to(device)\n",
    "#         attention_mask = data['attention_masks'].to(device)\n",
    "#         targets = data['targets'].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         _, preds = torch.max(outputs, dim=1)\n",
    "#         correct_predictions += torch.sum(preds == targets)\n",
    "#         total_samples += targets.size(0)\n",
    "#         losses.append(loss.item())\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "#         if scheduler: scheduler.step()\n",
    "#         progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "#     epoch_loss = np.mean(losses) if losses else 0\n",
    "#     epoch_acc = correct_predictions.double() / total_samples if total_samples > 0 else 0\n",
    "#     print(f'Train Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_acc:.4f}')\n",
    "#     return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "# def eval_model(model, criterion, data_loader, device, mode='Validation', n_epochs=EPOCHS, epoch=0):\n",
    "#     model.eval()\n",
    "#     losses = []\n",
    "#     correct_predictions = 0\n",
    "#     total_samples = 0\n",
    "#     progress_bar = tqdm(data_loader, desc=f'Epoch {epoch+1}/{n_epochs} [{mode}]', leave=False)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data in progress_bar:\n",
    "#             if data is None: continue\n",
    "#             input_ids = data['input_ids'].to(device)\n",
    "#             attention_mask = data['attention_masks'].to(device)\n",
    "#             targets = data['targets'].to(device)\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             _, preds = torch.max(outputs, dim=1)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             correct_predictions += torch.sum(preds == targets)\n",
    "#             total_samples += targets.size(0)\n",
    "#             losses.append(loss.item())\n",
    "\n",
    "#     epoch_loss = np.mean(losses) if losses else 0\n",
    "#     epoch_acc = correct_predictions.double() / total_samples if total_samples > 0 else 0\n",
    "#     print(f'{mode} Loss: {epoch_loss:.4f} | {mode} Accuracy: {epoch_acc:.4f}')\n",
    "#     return epoch_loss, epoch_acc\n",
    "# Cell 6 (SỬ DỤNG tqdm CƠ BẢN)\n",
    "\n",
    "# Import tqdm bản cơ bản (không cần ipywidgets)\n",
    "# Cell 6 (SỬ DỤNG tqdm CƠ BẢN - KIỂM TRA LẠI!)\n",
    "\n",
    "# Import tqdm bản cơ bản (không cần ipywidgets)\n",
    "from tqdm import tqdm # <<< QUAN TRỌNG: Đảm bảo là 'from tqdm import tqdm'\n",
    "import numpy as np\n",
    "import torch\n",
    "import traceback\n",
    "\n",
    "def train_epoch(model, criterion, optimizer, scheduler, train_loader, epoch, n_epochs, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    # Sử dụng tqdm bản cơ bản\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs} [Train]', leave=True, unit=\"batch\")\n",
    "\n",
    "    for data in progress_bar:\n",
    "        if data is None: continue\n",
    "        try:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_masks'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, targets)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            total_samples += targets.size(0)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            if scheduler: scheduler.step()\n",
    "            progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", refresh=True)\n",
    "        except Exception as e_batch:\n",
    "             print(f\"\\nError in training batch: {e_batch}\")\n",
    "             continue\n",
    "\n",
    "    epoch_loss = np.mean(losses) if losses else float('nan')\n",
    "    epoch_acc = correct_predictions.double() / total_samples if total_samples > 0 else float('nan')\n",
    "    print(f'Epoch {epoch+1}/{n_epochs} [Train] Completed - Train Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_acc:.4f}')\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def eval_model(model, criterion, data_loader, device, mode='Validation', n_epochs=EPOCHS, epoch=0):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    # Sử dụng tqdm bản cơ bản\n",
    "    progress_bar = tqdm(data_loader, desc=f'Epoch {epoch+1}/{n_epochs} [{mode}]', leave=True, unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in progress_bar:\n",
    "            if data is None: continue\n",
    "            try:\n",
    "                input_ids = data['input_ids'].to(device)\n",
    "                attention_mask = data['attention_masks'].to(device)\n",
    "                targets = data['targets'].to(device)\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                loss = criterion(outputs, targets)\n",
    "                correct_predictions += torch.sum(preds == targets)\n",
    "                total_samples += targets.size(0)\n",
    "                losses.append(loss.item())\n",
    "                progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", refresh=True)\n",
    "            except Exception as e_batch_eval:\n",
    "                 print(f\"\\nError in evaluation batch: {e_batch_eval}\")\n",
    "                 continue\n",
    "\n",
    "    epoch_loss = np.mean(losses) if losses else float('nan')\n",
    "    epoch_acc = correct_predictions.double() / total_samples if total_samples > 0 else float('nan')\n",
    "    print(f'Epoch {epoch+1}/{n_epochs} [{mode}] Completed - {mode} Loss: {epoch_loss:.4f} | {mode} Accuracy: {epoch_acc:.4f}')\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"Training and Evaluation functions defined (using basic tqdm).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: Training with K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold: 1/5 =====\n",
      "Fold 1: Train size=2048, Valid size=513\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]: 100%|██████████| 128/128 [00:51<00:00,  2.49batch/s, loss=0.9048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train] Completed - Train Loss: 0.8560 | Train Accuracy: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation]: 100%|██████████| 33/33 [00:03<00:00,  8.93batch/s, loss=2.2107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation] Completed - Validation Loss: 0.7174 | Validation Accuracy: 0.7349\n",
      "Validation accuracy improved (0.0000 --> 0.7349). Saving model...\n",
      "Model saved to phobert_sentiment_fold1.pth\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]: 100%|██████████| 128/128 [00:50<00:00,  2.53batch/s, loss=1.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train] Completed - Train Loss: 0.9548 | Train Accuracy: 0.6079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation]: 100%|██████████| 33/33 [00:03<00:00,  8.99batch/s, loss=1.4397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation] Completed - Validation Loss: 0.9554 | Validation Accuracy: 0.6062\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]: 100%|██████████| 128/128 [00:50<00:00,  2.53batch/s, loss=0.8699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train] Completed - Train Loss: 0.9415 | Train Accuracy: 0.6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation]: 100%|██████████| 33/33 [00:03<00:00,  8.99batch/s, loss=1.5729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation] Completed - Validation Loss: 0.9584 | Validation Accuracy: 0.6062\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]: 100%|██████████| 128/128 [00:50<00:00,  2.53batch/s, loss=0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train] Completed - Train Loss: 0.9333 | Train Accuracy: 0.6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation]: 100%|██████████| 33/33 [00:03<00:00,  9.01batch/s, loss=1.5941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation] Completed - Validation Loss: 0.9605 | Validation Accuracy: 0.6062\n",
      "\n",
      "Best Validation Accuracy for Fold 1: 0.7349\n",
      "\n",
      "===== Fold: 2/5 =====\n",
      "Fold 2: Train size=2049, Valid size=512\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.54batch/s, loss=1.5727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train] Completed - Train Loss: 0.8750 | Train Accuracy: 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.71batch/s, loss=1.1024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation] Completed - Validation Loss: 0.6711 | Validation Accuracy: 0.7227\n",
      "Validation accuracy improved (0.0000 --> 0.7227). Saving model...\n",
      "Model saved to phobert_sentiment_fold2.pth\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.54batch/s, loss=0.0716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train] Completed - Train Loss: 0.5517 | Train Accuracy: 0.7853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.69batch/s, loss=1.0733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation] Completed - Validation Loss: 0.5287 | Validation Accuracy: 0.7793\n",
      "Validation accuracy improved (0.7227 --> 0.7793). Saving model...\n",
      "Model saved to phobert_sentiment_fold2.pth\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.55batch/s, loss=0.6373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train] Completed - Train Loss: 0.4069 | Train Accuracy: 0.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.73batch/s, loss=1.2340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation] Completed - Validation Loss: 0.5090 | Validation Accuracy: 0.7910\n",
      "Validation accuracy improved (0.7793 --> 0.7910). Saving model...\n",
      "Model saved to phobert_sentiment_fold2.pth\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.56batch/s, loss=0.0840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train] Completed - Train Loss: 0.3194 | Train Accuracy: 0.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.74batch/s, loss=1.3531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation] Completed - Validation Loss: 0.4828 | Validation Accuracy: 0.8145\n",
      "Validation accuracy improved (0.7910 --> 0.8145). Saving model...\n",
      "Model saved to phobert_sentiment_fold2.pth\n",
      "\n",
      "Best Validation Accuracy for Fold 2: 0.8145\n",
      "\n",
      "===== Fold: 3/5 =====\n",
      "Fold 3: Train size=2049, Valid size=512\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.56batch/s, loss=0.2718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train] Completed - Train Loss: 1.1014 | Train Accuracy: 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.71batch/s, loss=1.3374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation] Completed - Validation Loss: 0.7030 | Validation Accuracy: 0.7246\n",
      "Validation accuracy improved (0.0000 --> 0.7246). Saving model...\n",
      "Model saved to phobert_sentiment_fold3.pth\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.55batch/s, loss=1.2672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train] Completed - Train Loss: 0.9610 | Train Accuracy: 0.5798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.74batch/s, loss=1.9438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation] Completed - Validation Loss: 1.0806 | Validation Accuracy: 0.6055\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.56batch/s, loss=0.3787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train] Completed - Train Loss: 0.8902 | Train Accuracy: 0.6310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.71batch/s, loss=1.6250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation] Completed - Validation Loss: 0.9881 | Validation Accuracy: 0.6055\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.57batch/s, loss=0.5282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train] Completed - Train Loss: 0.8723 | Train Accuracy: 0.6574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.77batch/s, loss=1.5836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation] Completed - Validation Loss: 0.9785 | Validation Accuracy: 0.6055\n",
      "\n",
      "Best Validation Accuracy for Fold 3: 0.7246\n",
      "\n",
      "===== Fold: 4/5 =====\n",
      "Fold 4: Train size=2049, Valid size=512\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.56batch/s, loss=0.5349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train] Completed - Train Loss: 0.8727 | Train Accuracy: 0.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.74batch/s, loss=1.1228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation] Completed - Validation Loss: 0.6327 | Validation Accuracy: 0.7578\n",
      "Validation accuracy improved (0.0000 --> 0.7578). Saving model...\n",
      "Model saved to phobert_sentiment_fold4.pth\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.55batch/s, loss=2.6360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train] Completed - Train Loss: 0.6255 | Train Accuracy: 0.7565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.74batch/s, loss=0.8246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation] Completed - Validation Loss: 0.4609 | Validation Accuracy: 0.8047\n",
      "Validation accuracy improved (0.7578 --> 0.8047). Saving model...\n",
      "Model saved to phobert_sentiment_fold4.pth\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.56batch/s, loss=0.4335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train] Completed - Train Loss: 0.4537 | Train Accuracy: 0.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.72batch/s, loss=1.0050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation] Completed - Validation Loss: 0.3936 | Validation Accuracy: 0.8398\n",
      "Validation accuracy improved (0.8047 --> 0.8398). Saving model...\n",
      "Model saved to phobert_sentiment_fold4.pth\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]: 100%|██████████| 129/129 [00:50<00:00,  2.55batch/s, loss=0.0669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train] Completed - Train Loss: 0.3645 | Train Accuracy: 0.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.72batch/s, loss=0.9058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation] Completed - Validation Loss: 0.3610 | Validation Accuracy: 0.8633\n",
      "Validation accuracy improved (0.8398 --> 0.8633). Saving model...\n",
      "Model saved to phobert_sentiment_fold4.pth\n",
      "\n",
      "Best Validation Accuracy for Fold 4: 0.8633\n",
      "\n",
      "===== Fold: 5/5 =====\n",
      "Fold 5: Train size=2049, Valid size=512\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   2%|▏         | 3/129 [00:01<00:46,  2.73batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 3.90 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   4%|▍         | 5/129 [00:01<00:35,  3.53batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   5%|▍         | 6/129 [00:01<00:38,  3.22batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   5%|▌         | 7/129 [00:02<00:39,  3.08batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   6%|▌         | 8/129 [00:02<00:40,  2.97batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   7%|▋         | 9/129 [00:03<00:41,  2.92batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   8%|▊         | 10/129 [00:03<00:40,  2.91batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   9%|▊         | 11/129 [00:03<00:42,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:   9%|▉         | 12/129 [00:04<00:41,  2.84batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  10%|█         | 13/129 [00:04<00:40,  2.84batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  11%|█         | 14/129 [00:04<00:40,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  12%|█▏        | 15/129 [00:05<00:40,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  12%|█▏        | 16/129 [00:05<00:40,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  13%|█▎        | 17/129 [00:05<00:39,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  14%|█▍        | 18/129 [00:06<00:39,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  15%|█▍        | 19/129 [00:06<00:39,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  16%|█▌        | 20/129 [00:06<00:39,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  16%|█▋        | 21/129 [00:07<00:39,  2.76batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  17%|█▋        | 22/129 [00:07<00:38,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  18%|█▊        | 23/129 [00:08<00:38,  2.75batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  19%|█▊        | 24/129 [00:08<00:37,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  19%|█▉        | 25/129 [00:08<00:37,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  20%|██        | 26/129 [00:09<00:37,  2.76batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  21%|██        | 27/129 [00:09<00:36,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  22%|██▏       | 28/129 [00:09<00:36,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  22%|██▏       | 29/129 [00:10<00:35,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  23%|██▎       | 30/129 [00:10<00:35,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  24%|██▍       | 31/129 [00:10<00:34,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  25%|██▍       | 32/129 [00:11<00:34,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  26%|██▌       | 33/129 [00:11<00:34,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  26%|██▋       | 34/129 [00:11<00:33,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  27%|██▋       | 35/129 [00:12<00:33,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  28%|██▊       | 36/129 [00:12<00:32,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  29%|██▊       | 37/129 [00:13<00:32,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  29%|██▉       | 38/129 [00:13<00:32,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  30%|███       | 39/129 [00:13<00:32,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  31%|███       | 40/129 [00:14<00:31,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  32%|███▏      | 41/129 [00:14<00:31,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  33%|███▎      | 42/129 [00:14<00:30,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  33%|███▎      | 43/129 [00:15<00:30,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  34%|███▍      | 44/129 [00:15<00:30,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  35%|███▍      | 45/129 [00:15<00:29,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  36%|███▌      | 46/129 [00:16<00:29,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  36%|███▋      | 47/129 [00:16<00:29,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  37%|███▋      | 48/129 [00:16<00:28,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  38%|███▊      | 49/129 [00:17<00:28,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  39%|███▉      | 50/129 [00:17<00:28,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  40%|███▉      | 51/129 [00:18<00:27,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  40%|████      | 52/129 [00:18<00:27,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  41%|████      | 53/129 [00:18<00:27,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  42%|████▏     | 54/129 [00:19<00:26,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  43%|████▎     | 55/129 [00:19<00:26,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  43%|████▎     | 56/129 [00:19<00:25,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  44%|████▍     | 57/129 [00:20<00:25,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  45%|████▍     | 58/129 [00:20<00:25,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  46%|████▌     | 59/129 [00:20<00:25,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  47%|████▋     | 60/129 [00:21<00:24,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  47%|████▋     | 61/129 [00:21<00:24,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  48%|████▊     | 62/129 [00:21<00:24,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  49%|████▉     | 63/129 [00:22<00:23,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  50%|████▉     | 64/129 [00:22<00:23,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  50%|█████     | 65/129 [00:23<00:22,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  51%|█████     | 66/129 [00:23<00:22,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  52%|█████▏    | 67/129 [00:23<00:22,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  53%|█████▎    | 68/129 [00:24<00:21,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  53%|█████▎    | 69/129 [00:24<00:21,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  54%|█████▍    | 70/129 [00:24<00:20,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  55%|█████▌    | 71/129 [00:25<00:20,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  56%|█████▌    | 72/129 [00:25<00:20,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  57%|█████▋    | 73/129 [00:25<00:19,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  57%|█████▋    | 74/129 [00:26<00:19,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  58%|█████▊    | 75/129 [00:26<00:19,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  59%|█████▉    | 76/129 [00:26<00:19,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  60%|█████▉    | 77/129 [00:27<00:18,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  60%|██████    | 78/129 [00:27<00:17,  2.85batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  61%|██████    | 79/129 [00:28<00:17,  2.85batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  62%|██████▏   | 80/129 [00:28<00:17,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  63%|██████▎   | 81/129 [00:28<00:17,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  64%|██████▎   | 82/129 [00:29<00:16,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  64%|██████▍   | 83/129 [00:29<00:16,  2.83batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  65%|██████▌   | 84/129 [00:29<00:16,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  66%|██████▌   | 85/129 [00:30<00:15,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  67%|██████▋   | 86/129 [00:30<00:15,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  67%|██████▋   | 87/129 [00:30<00:14,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  68%|██████▊   | 88/129 [00:31<00:14,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  69%|██████▉   | 89/129 [00:31<00:14,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  70%|██████▉   | 90/129 [00:31<00:14,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  71%|███████   | 91/129 [00:32<00:13,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  71%|███████▏  | 92/129 [00:32<00:13,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  72%|███████▏  | 93/129 [00:33<00:12,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  73%|███████▎  | 94/129 [00:33<00:12,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  74%|███████▎  | 95/129 [00:33<00:12,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  74%|███████▍  | 96/129 [00:34<00:11,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  75%|███████▌  | 97/129 [00:34<00:11,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  76%|███████▌  | 98/129 [00:34<00:11,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  77%|███████▋  | 99/129 [00:35<00:10,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  78%|███████▊  | 100/129 [00:35<00:10,  2.76batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  78%|███████▊  | 101/129 [00:35<00:10,  2.76batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  79%|███████▉  | 102/129 [00:36<00:09,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  80%|███████▉  | 103/129 [00:36<00:09,  2.76batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  81%|████████  | 104/129 [00:37<00:09,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  81%|████████▏ | 105/129 [00:37<00:08,  2.76batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  82%|████████▏ | 106/129 [00:37<00:08,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  83%|████████▎ | 107/129 [00:38<00:07,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  84%|████████▎ | 108/129 [00:38<00:07,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  84%|████████▍ | 109/129 [00:38<00:07,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  85%|████████▌ | 110/129 [00:39<00:06,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  86%|████████▌ | 111/129 [00:39<00:06,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  87%|████████▋ | 112/129 [00:39<00:06,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  88%|████████▊ | 113/129 [00:40<00:05,  2.80batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  88%|████████▊ | 114/129 [00:40<00:05,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  89%|████████▉ | 115/129 [00:40<00:05,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  90%|████████▉ | 116/129 [00:41<00:04,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  91%|█████████ | 117/129 [00:41<00:04,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  91%|█████████▏| 118/129 [00:42<00:03,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  92%|█████████▏| 119/129 [00:42<00:03,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  93%|█████████▎| 120/129 [00:42<00:03,  2.77batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  94%|█████████▍| 121/129 [00:43<00:02,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  95%|█████████▍| 122/129 [00:43<00:02,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  95%|█████████▌| 123/129 [00:43<00:02,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  96%|█████████▌| 124/129 [00:44<00:01,  2.78batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  97%|█████████▋| 125/129 [00:44<00:01,  2.81batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  98%|█████████▊| 126/129 [00:44<00:01,  2.82batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  98%|█████████▊| 127/129 [00:45<00:00,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]:  99%|█████████▉| 128/129 [00:45<00:00,  2.79batch/s, loss=0.8462]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train]: 100%|██████████| 129/129 [00:45<00:00,  2.81batch/s, loss=0.5604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Train] Completed - Train Loss: 0.9886 | Train Accuracy: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.75batch/s, loss=1.3186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 [Validation] Completed - Validation Loss: 0.9828 | Validation Accuracy: 0.6074\n",
      "Validation accuracy improved (0.0000 --> 0.6074). Saving model...\n",
      "Model saved to phobert_sentiment_fold5.pth\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   2%|▏         | 2/129 [00:00<00:26,  4.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   2%|▏         | 3/129 [00:00<00:34,  3.67batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   3%|▎         | 4/129 [00:01<00:38,  3.24batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   4%|▍         | 5/129 [00:01<00:40,  3.05batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   5%|▍         | 6/129 [00:01<00:41,  2.97batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   5%|▌         | 7/129 [00:02<00:42,  2.90batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   6%|▌         | 8/129 [00:02<00:41,  2.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   7%|▋         | 9/129 [00:02<00:41,  2.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   8%|▊         | 10/129 [00:03<00:42,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   9%|▊         | 11/129 [00:03<00:41,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:   9%|▉         | 12/129 [00:04<00:41,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  10%|█         | 13/129 [00:04<00:41,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  11%|█         | 14/129 [00:04<00:41,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  12%|█▏        | 15/129 [00:05<00:40,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  12%|█▏        | 16/129 [00:05<00:40,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  13%|█▎        | 17/129 [00:05<00:40,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  14%|█▍        | 18/129 [00:06<00:39,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  15%|█▍        | 19/129 [00:06<00:39,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  16%|█▌        | 20/129 [00:06<00:38,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  16%|█▋        | 21/129 [00:07<00:38,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  17%|█▋        | 22/129 [00:07<00:38,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  18%|█▊        | 23/129 [00:07<00:37,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  19%|█▊        | 24/129 [00:08<00:37,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  19%|█▉        | 25/129 [00:08<00:37,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  20%|██        | 26/129 [00:09<00:37,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  21%|██        | 27/129 [00:09<00:36,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  22%|██▏       | 28/129 [00:09<00:36,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  22%|██▏       | 29/129 [00:10<00:35,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  23%|██▎       | 30/129 [00:10<00:35,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  24%|██▍       | 31/129 [00:10<00:35,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  25%|██▍       | 32/129 [00:11<00:35,  2.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  26%|██▌       | 33/129 [00:11<00:34,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  26%|██▋       | 34/129 [00:11<00:34,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  27%|██▋       | 35/129 [00:12<00:33,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  28%|██▊       | 36/129 [00:12<00:33,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  29%|██▊       | 37/129 [00:13<00:33,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  29%|██▉       | 38/129 [00:13<00:32,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  30%|███       | 39/129 [00:13<00:32,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  31%|███       | 40/129 [00:14<00:32,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  32%|███▏      | 41/129 [00:14<00:31,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  33%|███▎      | 42/129 [00:14<00:31,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  33%|███▎      | 43/129 [00:15<00:30,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  34%|███▍      | 44/129 [00:15<00:30,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  35%|███▍      | 45/129 [00:15<00:30,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  36%|███▌      | 46/129 [00:16<00:29,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  36%|███▋      | 47/129 [00:16<00:29,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  37%|███▋      | 48/129 [00:16<00:28,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  38%|███▊      | 49/129 [00:17<00:28,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  39%|███▉      | 50/129 [00:17<00:28,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  40%|███▉      | 51/129 [00:18<00:28,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  40%|████      | 52/129 [00:18<00:27,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  41%|████      | 53/129 [00:18<00:26,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  42%|████▏     | 54/129 [00:19<00:26,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  43%|████▎     | 55/129 [00:19<00:26,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  43%|████▎     | 56/129 [00:19<00:26,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  44%|████▍     | 57/129 [00:20<00:25,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  45%|████▍     | 58/129 [00:20<00:25,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  46%|████▌     | 59/129 [00:20<00:24,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  47%|████▋     | 60/129 [00:21<00:24,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  47%|████▋     | 61/129 [00:21<00:24,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  48%|████▊     | 62/129 [00:21<00:23,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  49%|████▉     | 63/129 [00:22<00:23,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  50%|████▉     | 64/129 [00:22<00:23,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  50%|█████     | 65/129 [00:23<00:23,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  51%|█████     | 66/129 [00:23<00:22,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  52%|█████▏    | 67/129 [00:23<00:22,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  53%|█████▎    | 68/129 [00:24<00:21,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  53%|█████▎    | 69/129 [00:24<00:21,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  54%|█████▍    | 70/129 [00:24<00:21,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  55%|█████▌    | 71/129 [00:25<00:20,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  56%|█████▌    | 72/129 [00:25<00:20,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  57%|█████▋    | 73/129 [00:25<00:20,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  57%|█████▋    | 74/129 [00:26<00:19,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  58%|█████▊    | 75/129 [00:26<00:19,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  59%|█████▉    | 76/129 [00:26<00:18,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  60%|█████▉    | 77/129 [00:27<00:18,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  60%|██████    | 78/129 [00:27<00:18,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  61%|██████    | 79/129 [00:28<00:18,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  62%|██████▏   | 80/129 [00:28<00:17,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  63%|██████▎   | 81/129 [00:28<00:17,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  64%|██████▎   | 82/129 [00:29<00:16,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  64%|██████▍   | 83/129 [00:29<00:16,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  65%|██████▌   | 84/129 [00:29<00:16,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  66%|██████▌   | 85/129 [00:30<00:15,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  67%|██████▋   | 86/129 [00:30<00:15,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  67%|██████▋   | 87/129 [00:30<00:14,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  68%|██████▊   | 88/129 [00:31<00:14,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  69%|██████▉   | 89/129 [00:31<00:14,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  70%|██████▉   | 90/129 [00:31<00:13,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  71%|███████   | 91/129 [00:32<00:13,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  71%|███████▏  | 92/129 [00:32<00:13,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  72%|███████▏  | 93/129 [00:33<00:12,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  73%|███████▎  | 94/129 [00:33<00:12,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  74%|███████▎  | 95/129 [00:33<00:12,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  74%|███████▍  | 96/129 [00:34<00:11,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  75%|███████▌  | 97/129 [00:34<00:11,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  76%|███████▌  | 98/129 [00:34<00:11,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  77%|███████▋  | 99/129 [00:35<00:10,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  78%|███████▊  | 100/129 [00:35<00:10,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  78%|███████▊  | 101/129 [00:35<00:10,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  79%|███████▉  | 102/129 [00:36<00:09,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  80%|███████▉  | 103/129 [00:36<00:09,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  81%|████████  | 104/129 [00:36<00:08,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  81%|████████▏ | 105/129 [00:37<00:08,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  82%|████████▏ | 106/129 [00:37<00:08,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  83%|████████▎ | 107/129 [00:38<00:07,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  84%|████████▎ | 108/129 [00:38<00:07,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  84%|████████▍ | 109/129 [00:38<00:07,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  85%|████████▌ | 110/129 [00:39<00:06,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  86%|████████▌ | 111/129 [00:39<00:06,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  87%|████████▋ | 112/129 [00:39<00:06,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  88%|████████▊ | 113/129 [00:40<00:05,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  88%|████████▊ | 114/129 [00:40<00:05,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  89%|████████▉ | 115/129 [00:40<00:04,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  90%|████████▉ | 116/129 [00:41<00:04,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  91%|█████████ | 117/129 [00:41<00:04,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  91%|█████████▏| 118/129 [00:41<00:03,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  92%|█████████▏| 119/129 [00:42<00:03,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  93%|█████████▎| 120/129 [00:42<00:03,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  94%|█████████▍| 121/129 [00:43<00:02,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  95%|█████████▍| 122/129 [00:43<00:02,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  95%|█████████▌| 123/129 [00:43<00:02,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  96%|█████████▌| 124/129 [00:44<00:01,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  97%|█████████▋| 125/129 [00:44<00:01,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  98%|█████████▊| 126/129 [00:44<00:01,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  98%|█████████▊| 127/129 [00:45<00:00,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]:  99%|█████████▉| 128/129 [00:45<00:00,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 86.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train]: 100%|██████████| 129/129 [00:45<00:00,  2.81batch/s, loss=0.4848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Train] Completed - Train Loss: 0.9847 | Train Accuracy: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.82batch/s, loss=1.3195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 [Validation] Completed - Validation Loss: 0.9818 | Validation Accuracy: 0.6074\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   2%|▏         | 2/129 [00:00<00:28,  4.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   2%|▏         | 3/129 [00:00<00:35,  3.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   3%|▎         | 4/129 [00:01<00:38,  3.26batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   4%|▍         | 5/129 [00:01<00:40,  3.03batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   5%|▍         | 6/129 [00:01<00:41,  2.95batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   5%|▌         | 7/129 [00:02<00:42,  2.88batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   6%|▌         | 8/129 [00:02<00:41,  2.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   7%|▋         | 9/129 [00:02<00:41,  2.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   8%|▊         | 10/129 [00:03<00:41,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   9%|▊         | 11/129 [00:03<00:42,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:   9%|▉         | 12/129 [00:04<00:42,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  10%|█         | 13/129 [00:04<00:41,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  11%|█         | 14/129 [00:04<00:41,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  12%|█▏        | 15/129 [00:05<00:40,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  12%|█▏        | 16/129 [00:05<00:40,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  13%|█▎        | 17/129 [00:05<00:39,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  14%|█▍        | 18/129 [00:06<00:39,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  15%|█▍        | 19/129 [00:06<00:38,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  16%|█▌        | 20/129 [00:06<00:38,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  16%|█▋        | 21/129 [00:07<00:38,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  17%|█▋        | 22/129 [00:07<00:38,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  18%|█▊        | 23/129 [00:07<00:37,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  19%|█▊        | 24/129 [00:08<00:37,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  19%|█▉        | 25/129 [00:08<00:37,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  20%|██        | 26/129 [00:09<00:36,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  21%|██        | 27/129 [00:09<00:36,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  22%|██▏       | 28/129 [00:09<00:35,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  22%|██▏       | 29/129 [00:10<00:35,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  23%|██▎       | 30/129 [00:10<00:35,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  24%|██▍       | 31/129 [00:10<00:34,  2.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  25%|██▍       | 32/129 [00:11<00:34,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  26%|██▌       | 33/129 [00:11<00:34,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  26%|██▋       | 34/129 [00:11<00:33,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  27%|██▋       | 35/129 [00:12<00:33,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  28%|██▊       | 36/129 [00:12<00:33,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  29%|██▊       | 37/129 [00:12<00:32,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  29%|██▉       | 38/129 [00:13<00:32,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  30%|███       | 39/129 [00:13<00:32,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  31%|███       | 40/129 [00:14<00:31,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  32%|███▏      | 41/129 [00:14<00:31,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  33%|███▎      | 42/129 [00:14<00:30,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  33%|███▎      | 43/129 [00:15<00:30,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  34%|███▍      | 44/129 [00:15<00:30,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  35%|███▍      | 45/129 [00:15<00:29,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  36%|███▌      | 46/129 [00:16<00:29,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  36%|███▋      | 47/129 [00:16<00:29,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  37%|███▋      | 48/129 [00:16<00:29,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  38%|███▊      | 49/129 [00:17<00:28,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  39%|███▉      | 50/129 [00:17<00:28,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  40%|███▉      | 51/129 [00:17<00:27,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  40%|████      | 52/129 [00:18<00:27,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  41%|████      | 53/129 [00:18<00:26,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  42%|████▏     | 54/129 [00:18<00:26,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  43%|████▎     | 55/129 [00:19<00:25,  2.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  43%|████▎     | 56/129 [00:19<00:25,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  44%|████▍     | 57/129 [00:20<00:25,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  45%|████▍     | 58/129 [00:20<00:25,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  46%|████▌     | 59/129 [00:20<00:24,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  47%|████▋     | 60/129 [00:21<00:24,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  47%|████▋     | 61/129 [00:21<00:24,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  48%|████▊     | 62/129 [00:21<00:24,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  49%|████▉     | 63/129 [00:22<00:23,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  50%|████▉     | 64/129 [00:22<00:23,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  50%|█████     | 65/129 [00:22<00:22,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  51%|█████     | 66/129 [00:23<00:22,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  52%|█████▏    | 67/129 [00:23<00:22,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  53%|█████▎    | 68/129 [00:23<00:21,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  53%|█████▎    | 69/129 [00:24<00:21,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  54%|█████▍    | 70/129 [00:24<00:21,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  55%|█████▌    | 71/129 [00:25<00:20,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  56%|█████▌    | 72/129 [00:25<00:20,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  57%|█████▋    | 73/129 [00:25<00:19,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  57%|█████▋    | 74/129 [00:26<00:19,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  58%|█████▊    | 75/129 [00:26<00:19,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  59%|█████▉    | 76/129 [00:26<00:19,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  60%|█████▉    | 77/129 [00:27<00:18,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  60%|██████    | 78/129 [00:27<00:18,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  61%|██████    | 79/129 [00:27<00:18,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  62%|██████▏   | 80/129 [00:28<00:17,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  63%|██████▎   | 81/129 [00:28<00:17,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  64%|██████▎   | 82/129 [00:29<00:16,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  64%|██████▍   | 83/129 [00:29<00:16,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  65%|██████▌   | 84/129 [00:29<00:16,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  66%|██████▌   | 85/129 [00:30<00:15,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  67%|██████▋   | 86/129 [00:30<00:15,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  67%|██████▋   | 87/129 [00:30<00:15,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  68%|██████▊   | 88/129 [00:31<00:14,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  69%|██████▉   | 89/129 [00:31<00:14,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  70%|██████▉   | 90/129 [00:31<00:14,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  71%|███████   | 91/129 [00:32<00:13,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  71%|███████▏  | 92/129 [00:32<00:13,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  72%|███████▏  | 93/129 [00:32<00:12,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  73%|███████▎  | 94/129 [00:33<00:12,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  74%|███████▎  | 95/129 [00:33<00:12,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  74%|███████▍  | 96/129 [00:34<00:11,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  75%|███████▌  | 97/129 [00:34<00:11,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  76%|███████▌  | 98/129 [00:34<00:10,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  77%|███████▋  | 99/129 [00:35<00:10,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  78%|███████▊  | 100/129 [00:35<00:10,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  78%|███████▊  | 101/129 [00:35<00:09,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  79%|███████▉  | 102/129 [00:36<00:09,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  80%|███████▉  | 103/129 [00:36<00:09,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  81%|████████  | 104/129 [00:36<00:08,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  81%|████████▏ | 105/129 [00:37<00:08,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  82%|████████▏ | 106/129 [00:37<00:08,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  83%|████████▎ | 107/129 [00:37<00:07,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  84%|████████▎ | 108/129 [00:38<00:07,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  84%|████████▍ | 109/129 [00:38<00:07,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  85%|████████▌ | 110/129 [00:39<00:06,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  86%|████████▌ | 111/129 [00:39<00:06,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  87%|████████▋ | 112/129 [00:39<00:06,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  88%|████████▊ | 113/129 [00:40<00:05,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  88%|████████▊ | 114/129 [00:40<00:05,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  89%|████████▉ | 115/129 [00:40<00:04,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  90%|████████▉ | 116/129 [00:41<00:04,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  91%|█████████ | 117/129 [00:41<00:04,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  91%|█████████▏| 118/129 [00:41<00:03,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  92%|█████████▏| 119/129 [00:42<00:03,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  93%|█████████▎| 120/129 [00:42<00:03,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  94%|█████████▍| 121/129 [00:42<00:02,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  95%|█████████▍| 122/129 [00:43<00:02,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  95%|█████████▌| 123/129 [00:43<00:02,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  96%|█████████▌| 124/129 [00:44<00:01,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  97%|█████████▋| 125/129 [00:44<00:01,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  98%|█████████▊| 126/129 [00:44<00:01,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  98%|█████████▊| 127/129 [00:45<00:00,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]:  99%|█████████▉| 128/129 [00:45<00:00,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train]: 100%|██████████| 129/129 [00:45<00:00,  2.82batch/s, loss=0.6691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Train] Completed - Train Loss: 0.9846 | Train Accuracy: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.69batch/s, loss=1.3205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 [Validation] Completed - Validation Loss: 0.9807 | Validation Accuracy: 0.6074\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   2%|▏         | 2/129 [00:00<00:27,  4.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   2%|▏         | 3/129 [00:00<00:35,  3.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   3%|▎         | 4/129 [00:01<00:38,  3.23batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   4%|▍         | 5/129 [00:01<00:41,  3.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   5%|▍         | 6/129 [00:01<00:41,  2.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   5%|▌         | 7/129 [00:02<00:42,  2.90batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   6%|▌         | 8/129 [00:02<00:42,  2.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   7%|▋         | 9/129 [00:03<00:42,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   8%|▊         | 10/129 [00:03<00:42,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   9%|▊         | 11/129 [00:03<00:41,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:   9%|▉         | 12/129 [00:04<00:42,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  10%|█         | 13/129 [00:04<00:41,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  11%|█         | 14/129 [00:04<00:41,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  12%|█▏        | 15/129 [00:05<00:41,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  12%|█▏        | 16/129 [00:05<00:40,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  13%|█▎        | 17/129 [00:05<00:40,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  14%|█▍        | 18/129 [00:06<00:39,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  15%|█▍        | 19/129 [00:06<00:39,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  16%|█▌        | 20/129 [00:06<00:39,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  16%|█▋        | 21/129 [00:07<00:38,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  17%|█▋        | 22/129 [00:07<00:38,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  18%|█▊        | 23/129 [00:08<00:38,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  19%|█▊        | 24/129 [00:08<00:37,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  19%|█▉        | 25/129 [00:08<00:37,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  20%|██        | 26/129 [00:09<00:36,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  21%|██        | 27/129 [00:09<00:36,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  22%|██▏       | 28/129 [00:09<00:36,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  22%|██▏       | 29/129 [00:10<00:35,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  23%|██▎       | 30/129 [00:10<00:35,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  24%|██▍       | 31/129 [00:10<00:34,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  25%|██▍       | 32/129 [00:11<00:34,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  26%|██▌       | 33/129 [00:11<00:34,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  26%|██▋       | 34/129 [00:11<00:33,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  27%|██▋       | 35/129 [00:12<00:33,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  28%|██▊       | 36/129 [00:12<00:33,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  29%|██▊       | 37/129 [00:13<00:33,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  29%|██▉       | 38/129 [00:13<00:32,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  30%|███       | 39/129 [00:13<00:32,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  31%|███       | 40/129 [00:14<00:32,  2.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  32%|███▏      | 41/129 [00:14<00:31,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  33%|███▎      | 42/129 [00:14<00:31,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  33%|███▎      | 43/129 [00:15<00:31,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  34%|███▍      | 44/129 [00:15<00:30,  2.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  35%|███▍      | 45/129 [00:15<00:30,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  36%|███▌      | 46/129 [00:16<00:29,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  36%|███▋      | 47/129 [00:16<00:29,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  37%|███▋      | 48/129 [00:17<00:28,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  38%|███▊      | 49/129 [00:17<00:28,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  39%|███▉      | 50/129 [00:17<00:28,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  40%|███▉      | 51/129 [00:18<00:27,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  40%|████      | 52/129 [00:18<00:27,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  41%|████      | 53/129 [00:18<00:27,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  42%|████▏     | 54/129 [00:19<00:27,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  43%|████▎     | 55/129 [00:19<00:26,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  43%|████▎     | 56/129 [00:19<00:26,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  44%|████▍     | 57/129 [00:20<00:25,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  45%|████▍     | 58/129 [00:20<00:25,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  46%|████▌     | 59/129 [00:20<00:25,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  47%|████▋     | 60/129 [00:21<00:24,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  47%|████▋     | 61/129 [00:21<00:24,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  48%|████▊     | 62/129 [00:22<00:24,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  49%|████▉     | 63/129 [00:22<00:23,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  50%|████▉     | 64/129 [00:22<00:23,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  50%|█████     | 65/129 [00:23<00:22,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  51%|█████     | 66/129 [00:23<00:22,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  52%|█████▏    | 67/129 [00:23<00:22,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  53%|█████▎    | 68/129 [00:24<00:21,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  53%|█████▎    | 69/129 [00:24<00:21,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  54%|█████▍    | 70/129 [00:24<00:21,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  55%|█████▌    | 71/129 [00:25<00:20,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  56%|█████▌    | 72/129 [00:25<00:20,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  57%|█████▋    | 73/129 [00:25<00:20,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  57%|█████▋    | 74/129 [00:26<00:19,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  58%|█████▊    | 75/129 [00:26<00:19,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  59%|█████▉    | 76/129 [00:27<00:18,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  60%|█████▉    | 77/129 [00:27<00:18,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  60%|██████    | 78/129 [00:27<00:18,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  61%|██████    | 79/129 [00:28<00:18,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  62%|██████▏   | 80/129 [00:28<00:17,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  63%|██████▎   | 81/129 [00:28<00:17,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  64%|██████▎   | 82/129 [00:29<00:16,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  64%|██████▍   | 83/129 [00:29<00:16,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  65%|██████▌   | 84/129 [00:29<00:16,  2.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  66%|██████▌   | 85/129 [00:30<00:15,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  67%|██████▋   | 86/129 [00:30<00:15,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  67%|██████▋   | 87/129 [00:31<00:15,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  68%|██████▊   | 88/129 [00:31<00:14,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  69%|██████▉   | 89/129 [00:31<00:14,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  70%|██████▉   | 90/129 [00:32<00:14,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  71%|███████   | 91/129 [00:32<00:13,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  71%|███████▏  | 92/129 [00:32<00:13,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  72%|███████▏  | 93/129 [00:33<00:13,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  73%|███████▎  | 94/129 [00:33<00:12,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  74%|███████▎  | 95/129 [00:33<00:12,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  74%|███████▍  | 96/129 [00:34<00:11,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  75%|███████▌  | 97/129 [00:34<00:11,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  76%|███████▌  | 98/129 [00:35<00:11,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  77%|███████▋  | 99/129 [00:35<00:10,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  78%|███████▊  | 100/129 [00:35<00:10,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  78%|███████▊  | 101/129 [00:36<00:10,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  79%|███████▉  | 102/129 [00:36<00:09,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  80%|███████▉  | 103/129 [00:36<00:09,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  81%|████████  | 104/129 [00:37<00:08,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  81%|████████▏ | 105/129 [00:37<00:08,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  82%|████████▏ | 106/129 [00:37<00:08,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  83%|████████▎ | 107/129 [00:38<00:07,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  84%|████████▎ | 108/129 [00:38<00:07,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  84%|████████▍ | 109/129 [00:38<00:07,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  85%|████████▌ | 110/129 [00:39<00:06,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  86%|████████▌ | 111/129 [00:39<00:06,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  87%|████████▋ | 112/129 [00:40<00:06,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  88%|████████▊ | 113/129 [00:40<00:05,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  88%|████████▊ | 114/129 [00:40<00:05,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  89%|████████▉ | 115/129 [00:41<00:05,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  90%|████████▉ | 116/129 [00:41<00:04,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  91%|█████████ | 117/129 [00:41<00:04,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  91%|█████████▏| 118/129 [00:42<00:03,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  92%|█████████▏| 119/129 [00:42<00:03,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  93%|█████████▎| 120/129 [00:42<00:03,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  94%|█████████▍| 121/129 [00:43<00:02,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  95%|█████████▍| 122/129 [00:43<00:02,  2.79batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  95%|█████████▌| 123/129 [00:43<00:02,  2.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  96%|█████████▌| 124/129 [00:44<00:01,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  97%|█████████▋| 125/129 [00:44<00:01,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  98%|█████████▊| 126/129 [00:45<00:01,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  98%|█████████▊| 127/129 [00:45<00:00,  2.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]:  99%|█████████▉| 128/129 [00:45<00:00,  2.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in training batch: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 84.31 MiB is free. Including non-PyTorch memory, this process has 5.67 GiB memory in use. Of the allocated memory 4.07 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train]: 100%|██████████| 129/129 [00:46<00:00,  2.80batch/s, loss=1.8785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Train] Completed - Train Loss: 0.9943 | Train Accuracy: 0.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation]: 100%|██████████| 32/32 [00:03<00:00,  8.77batch/s, loss=1.3208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 [Validation] Completed - Validation Loss: 0.9787 | Validation Accuracy: 0.6074\n",
      "\n",
      "Best Validation Accuracy for Fold 5: 0.6074\n",
      "\n",
      "===== Training Complete =====\n",
      "Successfully trained 5/5 folds.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_fold_accuracies:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully trained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(best_fold_accuracies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_SPLITS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m folds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Best Validation Accuracy across successful folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_fold_accuracies\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed_folds:\n\u001b[1;32m    138\u001b[0m          \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(failed_folds)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# In ra các fold bị lỗi (loại bỏ trùng lặp)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:1194\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# Import tqdm nếu chưa import ở cell trước\n",
    "from tqdm import tqdm\n",
    "# Instead of PyTorch's AdamW\n",
    "from torch.optim import AdamW# Use this one which has correct_bias parameter\n",
    "import traceback # Để in chi tiết lỗi nếu có\n",
    "\n",
    "def prepare_loaders(df, fold, tokenizer, max_len, batch_size):\n",
    "    \"\"\"Chia dữ liệu và tạo DataLoaders cho một fold.\"\"\"\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    print(f\"Fold {fold+1}: Train size={len(df_train)}, Valid size={len(df_valid)}\")\n",
    "\n",
    "    if len(df_train) == 0 or len(df_valid) == 0:\n",
    "        print(f\"Warning: Empty train or validation set for fold {fold+1}. Skipping this fold.\")\n",
    "        return None, None # Trả về None nếu không có dữ liệu\n",
    "\n",
    "    train_dataset = SentimentDataset(df_train, tokenizer, max_len=max_len)\n",
    "    valid_dataset = SentimentDataset(df_valid, tokenizer, max_len=max_len)\n",
    "\n",
    "    try:\n",
    "        # Sử dụng num_workers=0 để đơn giản và ổn định hơn\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
    "        # Kiểm tra nhanh xem DataLoader có rỗng không (mặc dù collate_fn đã xử lý None items)\n",
    "        if len(train_loader) == 0 or len(valid_loader) == 0:\n",
    "             print(f\"Warning: DataLoader is empty for fold {fold+1} after creation. Skipping.\")\n",
    "             return None, None\n",
    "        return train_loader, valid_loader\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataLoader for fold {fold+1}: {e}\")\n",
    "        print(traceback.format_exc()) # In chi tiết lỗi\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# --- Biến lưu lịch sử và kết quả tốt nhất ---\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_fold_accuracies = []\n",
    "failed_folds = [] # Theo dõi các fold bị lỗi\n",
    "\n",
    "if all_df is not None:\n",
    "    # --- Vòng lặp K-Fold ---\n",
    "    for fold in range(N_SPLITS):\n",
    "        print(f'\\n===== Fold: {fold+1}/{N_SPLITS} =====')\n",
    "        fold_successful = True # Cờ để đánh dấu fold này có thành công không\n",
    "        best_val_acc = 0.0 # Reset best accuracy cho fold mới\n",
    "        fold_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "        try:\n",
    "            # Chuẩn bị DataLoader cho fold hiện tại\n",
    "            train_loader, valid_loader = prepare_loaders(all_df, fold, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "            # Bỏ qua fold này nếu DataLoader không được tạo\n",
    "            if train_loader is None or valid_loader is None:\n",
    "                failed_folds.append(fold + 1)\n",
    "                continue # Chuyển sang fold tiếp theo\n",
    "\n",
    "            # Khởi tạo lại model, criterion, optimizer, scheduler\n",
    "            model = SentimentClassifier(n_classes=N_CLASSES).to(device)\n",
    "            criterion = nn.CrossEntropyLoss().to(device)\n",
    "            optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "            # Tính tổng số bước huấn luyện (phải > 0)\n",
    "            num_training_steps = len(train_loader) * EPOCHS\n",
    "            if num_training_steps <= 0:\n",
    "                 print(f\"Warning: num_training_steps is zero or negative ({num_training_steps}) for fold {fold+1}. Skipping scheduler/training.\")\n",
    "                 failed_folds.append(fold + 1)\n",
    "                 continue\n",
    "\n",
    "            num_warmup_steps = int(0.1 * num_training_steps)\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=num_warmup_steps,\n",
    "                num_training_steps=num_training_steps\n",
    "            )\n",
    "\n",
    "            # Vòng lặp qua các Epoch\n",
    "            for epoch in range(EPOCHS):\n",
    "                print(f'\\n--- Epoch {epoch+1}/{EPOCHS} ---')\n",
    "                try:\n",
    "                    # Huấn luyện\n",
    "                    train_loss, train_acc = train_epoch(model, criterion, optimizer, scheduler, train_loader, epoch, EPOCHS, device)\n",
    "                    # Đánh giá\n",
    "                    val_loss, val_acc = eval_model(model, criterion, valid_loader, device, mode='Validation', n_epochs=EPOCHS, epoch=epoch)\n",
    "\n",
    "                    # Lưu lịch sử epoch này\n",
    "                    fold_history['train_loss'].append(train_loss)\n",
    "                    fold_history['train_acc'].append(train_acc)\n",
    "                    fold_history['val_loss'].append(val_loss)\n",
    "                    fold_history['val_acc'].append(val_acc)\n",
    "\n",
    "                    # Lưu model nếu validation accuracy tốt hơn và hợp lệ\n",
    "                    if torch.isfinite(torch.tensor(val_acc)) and val_acc > best_val_acc:\n",
    "                        print(f\"Validation accuracy improved ({best_val_acc:.4f} --> {val_acc:.4f}). Saving model...\")\n",
    "                        model_save_path = f'phobert_sentiment_fold{fold+1}.pth'\n",
    "                        try:\n",
    "                            torch.save(model.state_dict(), model_save_path)\n",
    "                            print(f\"Model saved to {model_save_path}\")\n",
    "                            best_val_acc = val_acc\n",
    "                        except Exception as e_save:\n",
    "                            print(f\"Error saving model for epoch {epoch+1}, fold {fold+1}: {e_save}\")\n",
    "                    elif not torch.isfinite(torch.tensor(val_acc)):\n",
    "                        print(f\"Warning: Invalid validation accuracy ({val_acc}) encountered in epoch {epoch+1}. Not saving model.\")\n",
    "\n",
    "                except Exception as e_epoch:\n",
    "                    print(f\"\\n!!! Error occurred during Epoch {epoch+1} for Fold {fold+1}: {e_epoch} !!!\")\n",
    "                    print(traceback.format_exc())\n",
    "                    print(\"Attempting to continue to the next epoch/fold...\")\n",
    "                    fold_successful = False # Đánh dấu fold này thất bại\n",
    "                    # Có thể thêm break ở đây nếu muốn dừng fold ngay khi có lỗi epoch\n",
    "                    # break # Bỏ comment nếu muốn dừng fold khi gặp lỗi epoch\n",
    "\n",
    "            # Kết thúc vòng lặp epoch cho fold hiện tại\n",
    "            if fold_successful:\n",
    "                print(f\"\\nBest Validation Accuracy for Fold {fold+1}: {best_val_acc:.4f}\")\n",
    "                best_fold_accuracies.append(best_val_acc)\n",
    "                # Lưu lịch sử của fold thành công vào history tổng\n",
    "                for key in history:\n",
    "                     history[key].extend(fold_history[key])\n",
    "            else:\n",
    "                print(f\"\\nFold {fold+1} encountered errors and might not have completed successfully.\")\n",
    "                failed_folds.append(fold + 1)\n",
    "\n",
    "\n",
    "        except Exception as e_fold:\n",
    "            # Xử lý lỗi xảy ra ngoài vòng lặp epoch (ví dụ: khi khởi tạo model/optimizer)\n",
    "            print(f\"\\n!!! Error occurred processing Fold {fold+1}: {e_fold} !!!\")\n",
    "            print(traceback.format_exc())\n",
    "            failed_folds.append(fold + 1)\n",
    "            continue # Chuyển sang fold tiếp theo\n",
    "\n",
    "\n",
    "    # --- Kết thúc vòng lặp K-Fold ---\n",
    "    print(f'\\n===== Training Complete =====')\n",
    "    if best_fold_accuracies:\n",
    "        print(f\"Successfully trained {len(best_fold_accuracies)}/{N_SPLITS} folds.\")\n",
    "        print(f\"Average Best Validation Accuracy across successful folds: {np.mean(best_fold_accuracies):.4f}\")\n",
    "        if failed_folds:\n",
    "             print(f\"Failed folds: {sorted(list(set(failed_folds)))}\") # In ra các fold bị lỗi (loại bỏ trùng lặp)\n",
    "    else:\n",
    "        print(f\"No folds were trained successfully. Failed folds: {sorted(list(set(failed_folds)))}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Cannot start training because data loading failed (all_df is None).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Testing with K-Fold Ensemble =====\n",
      "Loading model from: phobert_sentiment_fold1.pth\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Loading model from: phobert_sentiment_fold2.pth\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Loading model from: phobert_sentiment_fold3.pth\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Loading model from: phobert_sentiment_fold4.pth\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Loading model from: phobert_sentiment_fold5.pth\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Warning: Could not load model phobert_sentiment_fold5.pth. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 5.74 GiB memory in use. Of the allocated memory 5.43 GiB is allocated by PyTorch, and 200.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Ensemble):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Tiêu cực     0.7985    0.9390    0.8631       574\n",
      "  Trung bình     0.9149    0.3963    0.5531       434\n",
      "    Tích cực     0.8799    0.9620    0.9191      1553\n",
      "\n",
      "    accuracy                         0.8610      2561\n",
      "   macro avg     0.8644    0.7658    0.7784      2561\n",
      "weighted avg     0.8676    0.8610    0.8445      2561\n",
      "\n",
      "Overall Accuracy (Ensemble): 0.8610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Cell 8: Testing with K-Fold Ensemble (Sử dụng N_CLASSES=3, CLASS_NAMES)\n",
    "\n",
    "      \n",
    "def test_kfold_ensemble(df_test, tokenizer, max_len, batch_size, n_classes, class_names, n_splits, device):\n",
    "    print(\"\\n===== Testing with K-Fold Ensemble =====\")\n",
    "    test_dataset = SentimentDataset(df_test, tokenizer, max_len=max_len)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    models = []\n",
    "    for fold in range(n_splits):\n",
    "        model_path = f'phobert_sentiment_fold{fold+1}.pth'\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading model from: {model_path}\")\n",
    "            # Khởi tạo model với đúng số lớp\n",
    "            model = SentimentClassifier(n_classes=n_classes)\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "                models.append(model)\n",
    "            except Exception as e:\n",
    "                 print(f\"Warning: Could not load model {model_path}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Model file not found for fold {fold+1} at {model_path}\")\n",
    "\n",
    "    if not models:\n",
    "        print(\"Error: No models were loaded. Cannot perform testing.\")\n",
    "        return None, None, None\n",
    "\n",
    "    texts = []\n",
    "    predicts_ensemble = []\n",
    "    predict_probs_ensemble = []\n",
    "    real_values = []\n",
    "    progress_bar = tqdm(test_loader, desc='Testing Ensemble', leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in progress_bar:\n",
    "            if data is None: continue\n",
    "            text_batch = data['text']\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_masks'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            batch_outputs = [model(input_ids, attention_mask) for model in models]\n",
    "            stacked_outputs = torch.stack(batch_outputs)\n",
    "            mean_outputs = torch.mean(stacked_outputs, dim=0)\n",
    "            _, preds = torch.max(mean_outputs, dim=1)\n",
    "\n",
    "            texts.extend(text_batch)\n",
    "            predicts_ensemble.extend(preds)\n",
    "            predict_probs_ensemble.extend(torch.softmax(mean_outputs, dim=1))\n",
    "            real_values.extend(targets)\n",
    "\n",
    "    if not real_values:\n",
    "         print(\"Warning: No samples were processed during testing.\")\n",
    "         return None, None, None\n",
    "\n",
    "    predicts_ensemble = torch.stack(predicts_ensemble).cpu().numpy()\n",
    "    real_values = torch.stack(real_values).cpu().numpy()\n",
    "\n",
    "    print(\"\\nClassification Report (Ensemble):\")\n",
    "    # Sử dụng class_names đã định nghĩa (3 lớp)\n",
    "    print(classification_report(real_values, predicts_ensemble, target_names=class_names, digits=4))\n",
    "    accuracy = accuracy_score(real_values, predicts_ensemble)\n",
    "    print(f\"Overall Accuracy (Ensemble): {accuracy:.4f}\")\n",
    "\n",
    "    return real_values, predicts_ensemble, texts\n",
    "\n",
    "# Chạy đánh giá trên toàn bộ dữ liệu all_df\n",
    "if all_df is not None:\n",
    "     real_labels_test, predicted_labels_test, original_texts_test = test_kfold_ensemble(\n",
    "         all_df, tokenizer, MAX_LEN, BATCH_SIZE, N_CLASSES, CLASS_NAMES, N_SPLITS, device\n",
    "     )\n",
    "else:\n",
    "     print(\"Cannot run testing because data loading failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'real_labels_test' in locals() and real_labels_test is not None:\n",
    "    cm = confusion_matrix(real_labels_test, predicted_labels_test)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Sử dụng CLASS_NAMES 3 lớp\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix (Ensemble Predictions)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot plot heatmap because testing results are not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Misclassified Examples ---\n",
      "Total misclassified samples: 356\n",
      "\n",
      "Displaying 15 random misclassified samples:\n",
      "                                                                                                                                                                                Sentence  \\\n",
      "648   mua chưa được 20 ngày mà bị hư 2 lần. mà 1 lần đợi xuống coi thì 3, 4 ngày. giờ ngồi ngó chứ có sử dụng được đâu. mua hàng bên điện máy xanh rất nhiều nhưng lần này thất vọng quá   \n",
      "67                                                                                                                                                                      quạt chạy êm mat   \n",
      "1151                                                      máy ép mới dùng lần đầu tiên ép tách nước ok, nhưng qua lần thứ 2 trở đi thì ép giống như nước sinh tố, có xác ở trong nước ép   \n",
      "2493                                                                                                                                                                              khá ổn   \n",
      "121                                                                                                                                               mua về mới một ngày sao bị chảy nước ạ   \n",
      "1288                                                                                                                             máy khoẻ chạy e nhân viên giao hàng đúng giờ thân thiện   \n",
      "855                                                                                                                                                                          cũng được   \n",
      "1690                                                                                                                                                                     hàng dùng được.   \n",
      "453                                                                                                                                                       quạt chạy êm. máy. nên mua nha   \n",
      "345                                                                                                                                sp mới mà mới vừa đổ nước vào là bị rỉ chỗ nút xả cặn   \n",
      "2449                  Bình chất liệu tốt bên trong lòng bình bằng inox nên an tâm sử dụng. Điểm trừ duy nhất là nắp bình hơi khó mở mỗi lần lấy nước vào.Nhưng nhìn chung vẫn là sp tốt.   \n",
      "1916                                                   Hàng nhìn ổn.\\nChất lượng thì phải để trãi nghiệm. \\nĐóng gói tiêu chuẩn. \\nGiao trễ 2 ngày, chắc do dịch!\\nVẫn vote 5 để ủng hộ.   \n",
      "1997                                                                                                                                                    Đun sôi trong vòng 3p, khá nhanb   \n",
      "750                                                                                      máy chạy quá ồn! gió yếu! khi sử dụng xong sáng hơi nước rít rít người! khuyên nên mua máy lạnh   \n",
      "662                                                        nhân viên vận chuyển hướng dẫn cách chăm nước sai cho mình  lần chăm nước tiếp theo làm theo hướng dẫn thì nước tràn ra ngoài   \n",
      "\n",
      "      Real_Label Predicted_Label  \n",
      "648     Tích cực        Tiêu cực  \n",
      "67    Trung bình        Tích cực  \n",
      "1151    Tích cực        Tiêu cực  \n",
      "2493  Trung bình        Tích cực  \n",
      "121   Trung bình        Tiêu cực  \n",
      "1288  Trung bình        Tích cực  \n",
      "855   Trung bình        Tích cực  \n",
      "1690  Trung bình        Tích cực  \n",
      "453   Trung bình        Tích cực  \n",
      "345   Trung bình        Tiêu cực  \n",
      "2449  Trung bình        Tích cực  \n",
      "1916  Trung bình        Tiêu cực  \n",
      "1997  Trung bình        Tích cực  \n",
      "750   Trung bình        Tiêu cực  \n",
      "662   Trung bình        Tiêu cực  \n",
      "\n",
      "Common Misclassification Pairs (Real -> Predicted):\n",
      "Real_Label  Predicted_Label\n",
      "Trung bình  Tích cực           177\n",
      "            Tiêu cực            85\n",
      "Tích cực    Tiêu cực            51\n",
      "Tiêu cực    Tích cực            27\n",
      "            Trung bình           8\n",
      "Tích cực    Trung bình           8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_wrong(real_values, predicts, df_source, class_names):\n",
    "    wrong_df_list = []\n",
    "    for i in range(len(predicts)):\n",
    "        if predicts[i] != real_values[i]:\n",
    "            original_row = df_source.iloc[i].copy()\n",
    "            original_row['Predicted_Label_Index'] = predicts[i]\n",
    "            original_row['Real_Label_Index'] = real_values[i]\n",
    "            # Lấy tên lớp từ class_names\n",
    "            original_row['Predicted_Label'] = class_names[predicts[i]]\n",
    "            original_row['Real_Label'] = class_names[real_values[i]]\n",
    "            wrong_df_list.append(original_row)\n",
    "    if not wrong_df_list: return pd.DataFrame()\n",
    "    return pd.DataFrame(wrong_df_list)\n",
    "\n",
    "if 'real_labels_test' in locals() and real_labels_test is not None and all_df is not None:\n",
    "    print(\"\\n--- Analyzing Misclassified Examples ---\")\n",
    "    # Sử dụng CLASS_NAMES 3 lớp\n",
    "    wrong_predictions_df = check_wrong(real_labels_test, predicted_labels_test, all_df, CLASS_NAMES)\n",
    "\n",
    "    if not wrong_predictions_df.empty:\n",
    "        print(f\"Total misclassified samples: {len(wrong_predictions_df)}\")\n",
    "        num_samples_to_show = min(15, len(wrong_predictions_df))\n",
    "        print(f\"\\nDisplaying {num_samples_to_show} random misclassified samples:\")\n",
    "        pd.set_option('display.max_colwidth', 200)\n",
    "        # Hiển thị cột Sentence, Real_Label, Predicted_Label\n",
    "        print(wrong_predictions_df.sample(num_samples_to_show)[['Sentence', 'Real_Label', 'Predicted_Label']])\n",
    "\n",
    "        print(\"\\nCommon Misclassification Pairs (Real -> Predicted):\")\n",
    "        print(wrong_predictions_df.groupby(['Real_Label', 'Predicted_Label']).size().sort_values(ascending=False))\n",
    "    else:\n",
    "        print(\"Congratulations! No misclassified examples found in the test set!\")\n",
    "else:\n",
    "    print(\"Cannot show misclassified examples because testing results or original data are not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Inference Examples ---\n",
      "\n",
      "--- Inference ---\n",
      "Input Text: quạt này dùng thích thật sự, mát mà êm\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Warning: Could not load model phobert_sentiment_fold5.pth. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 5.74 GiB memory in use. Of the allocated memory 5.43 GiB is allocated by PyTorch, and 200.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Processed Text: quạt này dùng thích thật_sự mát mà êm\n",
      "Predicted Label: Tích cực\n",
      "Probabilities: {'Tiêu cực': '0.0277', 'Trung bình': '0.0673', 'Tích cực': '0.9050'}\n",
      "--------------------\n",
      "\n",
      "--- Inference ---\n",
      "Input Text: chất lượng quá kém, mới mua đã kêu to, không làm mát\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Warning: Could not load model phobert_sentiment_fold5.pth. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 5.74 GiB memory in use. Of the allocated memory 5.43 GiB is allocated by PyTorch, and 200.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Processed Text: chất_lượng quá kém mới mua đã kêu to không làm mát\n",
      "Predicted Label: Tiêu cực\n",
      "Probabilities: {'Tiêu cực': '0.7481', 'Trung bình': '0.1259', 'Tích cực': '0.1259'}\n",
      "--------------------\n",
      "\n",
      "--- Inference ---\n",
      "Input Text: quạt cũng bình thường, làm mát tạm được, hơi ồn chút\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Initializing SentimentClassifier for 3 classes...\n",
      "Pre-trained PhoBERT base model loaded.\n",
      "Classifier head initialized.\n",
      "Warning: Could not load model phobert_sentiment_fold5.pth. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 5.77 GiB of which 18.31 MiB is free. Including non-PyTorch memory, this process has 5.74 GiB memory in use. Of the allocated memory 5.43 GiB is allocated by PyTorch, and 200.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Processed Text: quạt cũng bình_thường làm mát tạm được hơi ồn chút\n",
      "Predicted Label: Tích cực\n",
      "Probabilities: {'Tiêu cực': '0.1639', 'Trung bình': '0.1750', 'Tích cực': '0.6610'}\n"
     ]
    }
   ],
   "source": [
    "def infer_ensemble(text, tokenizer, max_len, n_classes, class_names, n_splits, device):\n",
    "    print(f'\\n--- Inference ---')\n",
    "    print(f'Input Text: {text}')\n",
    "\n",
    "    # 1. Load models\n",
    "    models = []\n",
    "    for fold in range(n_splits):\n",
    "        model_path = f'phobert_sentiment_fold{fold+1}.pth'\n",
    "        if os.path.exists(model_path):\n",
    "            # Khởi tạo model với đúng số lớp\n",
    "            model = SentimentClassifier(n_classes=n_classes)\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "                models.append(model)\n",
    "            except Exception as e:\n",
    "                 print(f\"Warning: Could not load model {model_path}. Error: {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: Model file not found for fold {fold+1} at {model_path}\")\n",
    "\n",
    "    if not models:\n",
    "        print(\"Error: No models loaded for inference.\")\n",
    "        return \"Error: No models available\", {}\n",
    "\n",
    "    # 2. Preprocess text\n",
    "    processed_text = ' '.join(simple_preprocess(text))\n",
    "    tokenized_text = ViTokenizer.tokenize(processed_text)\n",
    "\n",
    "    # 3. Encode text\n",
    "    try:\n",
    "        encoded_input = tokenizer.encode_plus(\n",
    "            tokenized_text, max_length=max_len, truncation=True,\n",
    "            add_special_tokens=True, padding='max_length',\n",
    "            return_attention_mask=True, return_token_type_ids=False,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding input text: {e}\")\n",
    "        return \"Error: Encoding failed\", {}\n",
    "\n",
    "    input_ids = encoded_input['input_ids'].to(device)\n",
    "    attention_mask = encoded_input['attention_mask'].to(device)\n",
    "\n",
    "    # 4. Ensemble Prediction\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            all_outputs.append(outputs)\n",
    "\n",
    "    # 5. Average results and get prediction\n",
    "    stacked_outputs = torch.stack(all_outputs)\n",
    "    mean_outputs = torch.mean(stacked_outputs, dim=0)\n",
    "    probabilities = torch.softmax(mean_outputs, dim=1)[0]\n",
    "    final_pred_index = torch.argmax(mean_outputs, dim=1).item()\n",
    "\n",
    "    # Sử dụng class_names 3 lớp\n",
    "    predicted_label = class_names[final_pred_index]\n",
    "\n",
    "    print(f'Processed Text: {tokenized_text}')\n",
    "    print(f'Predicted Label: {predicted_label}')\n",
    "    prob_dict = {name: f\"{prob.item():.4f}\" for name, prob in zip(class_names, probabilities.cpu())}\n",
    "    print(f'Probabilities: {prob_dict}')\n",
    "    return predicted_label, prob_dict\n",
    "\n",
    "# --- Chạy thử Inference ---\n",
    "if 'tokenizer' in locals() and N_SPLITS > 0:\n",
    "     print(\"\\n--- Running Inference Examples ---\")\n",
    "     # Ví dụ cần có đủ 3 lớp trong dữ liệu huấn luyện để có ý nghĩa\n",
    "     infer_ensemble('quạt này dùng thích thật sự, mát mà êm', tokenizer, MAX_LEN, N_CLASSES, CLASS_NAMES, N_SPLITS, device)\n",
    "     print(\"-\" * 20)\n",
    "     infer_ensemble('chất lượng quá kém, mới mua đã kêu to, không làm mát', tokenizer, MAX_LEN, N_CLASSES, CLASS_NAMES, N_SPLITS, device)\n",
    "     print(\"-\" * 20)\n",
    "     infer_ensemble('quạt cũng bình thường, làm mát tạm được, hơi ồn chút', tokenizer, MAX_LEN, N_CLASSES, CLASS_NAMES, N_SPLITS, device) # Ví dụ cho lớp trung bình\n",
    "else:\n",
    "     print(\"\\nCannot run inference example. Tokenizer not loaded or no models trained.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
